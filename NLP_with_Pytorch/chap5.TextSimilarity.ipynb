{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = '''\n",
    "지능 지수 라는 말 들 어 보 셨 을 겁니다 . 여러분 의 지성 을 일컫 는 말 이 죠 . 그런데 심리 지수 란 건 뭘까요 ? 사람 들 이 특정 한 식 으로 행동 하 는 이유 에 대해 여러분 은 얼마나 알 고 계시 나요 ? 또 타인 이나 심지어 여러분 의 행동 을 예측 하 는 일 은 얼마나 잘 하 시 나요 ? 또 , 심리학 에 대해 갖춘 지식 중 에서 어느 정도 나 잘못 된 것 일까요 ? 심리학 에 관한 열 가지 신화 를 통해 잘못 된 것 들 을 알아보 도록 하 죠 . 여러분 은 한 번 쯤 들 어 보 셨 을 법 한 것 은 자신 들 의 심리학 에 대해 고려 할 때 , 거의 항상 남자 는 화성 에서 왔 고 , 여자 는 금성 에서 온 것 같 다고 합니다 . 하지만 실제로 남자 와 여자 는 얼마나 다른 걸까요 ? 이 를 알아보 기 위해 , 일단 남녀 사이 에 확실 하 게 차이 나 는 것 을 살펴보 고 심리학 적 인 성별 간 의 차이점 을 동일 한 척도 상 에서 대비 해 보 도록 하 겠 습니다 . 남자 와 여자 간 에 실제로 차이 나 는 능력 중 하나 는 그 들 이 공 을 얼마나 멀리 던질 수 있 느냐 하 는 것 입니다 . 여기 남자 들 의 데 이타 를 보 시 면 , 정상 분포 곡선 이 라는 걸 볼 수 있 습니다 . 남자 들 소수 는 정말 멀리 던지 고 , 남자 들 소수 는 멀리 던지 지 못하 지만 , 남자 들 대부분 은 평균 적 인 거리 를 던졌 습니다 . 여자 들 도 역시 비슷 한 분포 상태 를 보입니다 만 사실 남녀 사이 엔 커다란 차이 가 있 습니다 . 사실 , 평균 수준 의 남자 라면 모든 여성 중 대략 98 % 보다 더 멀리 던질 수 있 거든요 . 이 와 동일 하 게 표준 화 된 척도 상 에서 심리학 에서 말 하 는 성별 간 의 차이 를 살펴 봅시다 . 심리학자 라는 여러분 에게 말 하 길 남자 들 의 공간 지각 능력 이 여자 들 보다 뛰어나 다고 할 겁니다 . 예 를 들 어 , 지도 읽 는 능력 같 은 건데 , 맞 는 말 입니다 . 하지만 그 차이 의 정도 를 살펴봅시다 . 아주 작 죠 . 두 선 이 너무 근접 해서 거의 겹칠 정도 입니다 .\n",
    "'''\n",
    "\n",
    "doc2 = '''\n",
    "최상 의 제시 유형 은 학습 자 에 좌우 되 는 것 이 아니 라 학습 해야 할 내용 에 따라 좌우 됩니다 . 예 를 들 어 여러분 이 운전 하 기 를 배울 때 실제로 몸 으로 체감 하 는 경험 없이 누군가 가 어떻게 할 지 이야기 하 는 것 을 듣 는 것 만 으로 배울 수 있 습니까 ? 연립 방정식 을 풀 어야 하 는데 종이 에 쓰 지 않 고 머리 속 에서 말 하 는 것 으로 풀 수 가 있 을까요 ? 또는 만일 여러분 이 체감 형식 의 학습 자 유형 이 라면 , 건축학 시험 을 해석 적 춤 을 이용 하 여 수정 할 수 있 을까요 ? 아니 죠 ! 배워야 할 내용 을 제시 된 유형 에 맞추 어야 합니다 , 당신 에게 맞추 는 게 아니 라요 . 여러분 들 상당수 가 \" A \" 급 의 우등 생 이 라는 걸 아 는데 , 조만간 중등 학력 인증 시험 ( GCSE ) 결과 를 받 게 되 시 겠 네요 . 그런데 , 만일 , 여러분 들 이 희망 했 던 성적 을 받 지 못하 게 된다 해도 여러분 들 의 학습 방식 을 탓 해서 는 안 되 는 겁니다 . 여러분 이 비난 할 수 있 는 한 가지 는 바로 유전자 입니다 . 이건 최근 에 런던 대학교 ( UCL ) 에서 수행 했 던 연구 결과 는 여러 학생 들 과 그 들 의 중등 학력 인증 시험 결과 사이 의 차이 중 58 % 는 유전 적 인 요인 으로 좁혀졌 습니다 . 매우 정밀 한 수치 처럼 들립니다 . 그러면 어떻게 알 수 있 을까요 ? 유전 적 요인 과 환경 적 요인 의 상대 적 기여 도 를 알 고 싶 을 때 우리 가 사용 할 수 있 는 방식 은 바로 쌍둥이 연구 입니다 . 일 란 성 쌍생아 의 경우 환경 적 요인 과 유전 적 요인 모두 를 100 % 똑같이 공유 하 게 되 지만 이란 성 쌍생아 의 경우 는 100 % 동일 한 환경 을 공유 하 지만 유전자 의 경우 여타 의 형제자매 들 처럼 50 % 만 공유 하 게 됩니다 . 따라서 일 란 성 쌍둥이 와 이란 성 쌍둥이 사이 의 인증 시험 결과 가 얼마나 비슷 한지 비교 해 보 고 여기 에 약간 의 수학 적 계산 을 더하 게 되 면 그 수행 능력 의 차이 중 어느 정도 가 환경 적 요인 의 탓 이 고 어느 정도 가 유전자 탓 인지 를 알 수 있 게 됩니다 .\n",
    "'''\n",
    "\n",
    "doc3 = '''\n",
    "그러나 이 이야기 는 세 가지 이유 로 인해 신화 입니다 . 첫째 , 가장 중요 한 건 실험실 가운 은 흰색 이 아니 라 회색 이 었 다 라는 점 이 죠 . 둘째 , 참 여자 들 은 실험 하 기 전 에 와 참여 자 들 이 걱정 을 표현 할 때 마다 상기 시키 는 말 을 들 었 는데 , 전기 충격 이 고통 스럽 기 는 하 지만 , 치명 적 이 지 는 않 으며 실제로 영구 적 인 손상 을 남기 는 일 은 없 을 거 라는 것 이 었 습니다 . 셋째 , 참 여자 들 은 단지 가운 을 입 은 사람 이 시켜 전기 충격 을 주지 는 않 았 죠 . 실험 이 끝나 고 그 들 의 인터뷰 를 했 을 때 모든 참여 자 들 은 강한 신념 을 밝혔 는데 , ' 학습 과 처벌 ' 연구 가 과학 적 으로 가치 있 는 목적 을 수행 했 기 때문 에 비록 동료 참여 자 들 에게 가해진 순간 적 인 불편 함 에 반해서 과학 을 위해서 오래 남 을 성과 를 얻 을 것 이 라고 말 이 죠 . 그러 다 보 니 제 가 이야기 를 한 지 벌써 12 분 이 되 었 습니다 . 여러분 들 중 에 는 아마 거기 앉 아서 제 이야기 를 들으시는 동안 저 의 말투 와 몸짓 을 분석 하 면서 제 가 말 하 는 어떤 것 을 인지 해야 할까 해결 하 려고 하 셨 을 겁니다 , 제 가 진실 을 이야기 하 는 지 , 또는 거짓말 을 하 고 있 는 것 인지 말 이 죠 . 만일 그러 셨 다면 , 아마 지금 쯤 완전히 실패 하 셨 을 겁니다 . 왜냐하면 우리 모두 가 사람 이 말 하 는 패턴 과 몸짓 으로 도 거짓말 여부 를 알아내 는 것 이 가능 하 다고 생각 하 지만 , 오랜 세월 수백 회 에 걸쳐 행해진 실제 심리 검사 의 결과 를 보 면 우리 들 모두 는 , 심지어 경찰관 이나 탐정 들 을 포함 해서 도 기본 적 으로 몸짓 과 언어 적 패턴 으로 거짓말 을 탐지 하 는 것 은 운 에 맞 길 수 밖 에 는 없 는 것 입니다 . 흥미 롭 게 도 한 가지 예외 가 있 는데요 : 실종 된 친척 을 찾 아 달 라고 호소 하 는 TV 홍보 입니다 .'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "## 문서 내 단어의 출현빈도 세기\n",
    "def get_term_frequency(document, word_dict = None):\n",
    "    if word_dict is None:\n",
    "        word_dict = {}\n",
    "    words = document.split()\n",
    "    '''\n",
    "    str.split(sep=None, maxsplit=-1)\n",
    "    https://docs.python.org/ko/3/library/stdtypes.html?highlight=split#str.split\n",
    "    문자열을 구분자 기준으로 나누어서 maxsplit+1개의 요소를 가진 리스트로 반환함\n",
    "    '''\n",
    "    \n",
    "    for w in words:\n",
    "        word_dict[w] = 1 + (0 if word_dict.get(w) is None else word_dict[w])\n",
    "    '''\n",
    "    words 리스트 요소들을 key로 추가하면서 셈\n",
    "    특정 단어 최초 등장시 key 값은 1 1 + (0 if word_dict.get(w) is None)\n",
    "    두번 이상 등장 시 key 값은 1 + word_dict[w](이전까지 등장한 총합)\n",
    "    '''\n",
    "        \n",
    "    return pd.Series(word_dict).sort_values(ascending = False)\n",
    "    '''\n",
    "    index:단어, value:등장 횟수 인 Series로 return\n",
    "    '''\n",
    "\n",
    "\n",
    "## 각 단어의 몇 개의 문서에서 나타났는지 (IDF) 세기\n",
    "def get_document_frequency(documents):\n",
    "    dicts = []\n",
    "    vocab = set([])\n",
    "    df = {}\n",
    "    \n",
    "    for d in documents:\n",
    "        tf = get_term_frequency(d) # tf = document d의 단어별 등장횟수 series\n",
    "        dicts += [tf]\n",
    "        print(dicts)\n",
    "        print(type(dicts))\n",
    "        print('dicts의 길이',len(dicts))\n",
    "        print(\"========================\")\n",
    "        \n",
    "        vocab = vocab | set(tf.keys())  ## set | set 은 합집합을 의미하는 듯?\n",
    "        print(vocab)\n",
    "        print(type(vocab))\n",
    "        \n",
    "    for v in list(vocab):\n",
    "        df[v] = 0\n",
    "        for dict_d in dicts:\n",
    "            if dict_d.get(v) is not None:\n",
    "                df[v] += 1\n",
    "                \n",
    "    return pd.Series(df).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "test1 = set([1,2,3,4,5])\n",
    "test2 = set([2,3,4,5,6])\n",
    "print(test1|test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.get('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".     16\n",
       "는     15\n",
       "들     14\n",
       ",     10\n",
       "하     10\n",
       "      ..\n",
       "정상     1\n",
       "면      1\n",
       "이타     1\n",
       "데      1\n",
       "지능     1\n",
       "Length: 186, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_term_frequency(doc1)\n",
    "## class list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_term_frequency(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     113\n",
       "2      33\n",
       "3      13\n",
       "5       7\n",
       "4       6\n",
       "6       4\n",
       "8       3\n",
       "10      2\n",
       "9       2\n",
       "16      1\n",
       "15      1\n",
       "14      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['.', '는', '들', ',', '하', '의', '남자', '을', '를', '이',\n",
       "       ...\n",
       "       '지', '정말', '볼', '걸', '곡선', '정상', '면', '이타', '데', '지능'],\n",
       "      dtype='object', length=186)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.keys of .     16\n",
       "는     15\n",
       "들     14\n",
       ",     10\n",
       "하     10\n",
       "      ..\n",
       "정상     1\n",
       "면      1\n",
       "이타     1\n",
       "데      1\n",
       "지능     1\n",
       "Length: 186, dtype: int64>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 15, 14, 10, 10,  9,  9,  8,  8,  8,  6,  6,  6,  6,  5,  5,  5,\n",
       "        5,  5,  5,  5,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[.     16\n",
      "는     15\n",
      "들     14\n",
      ",     10\n",
      "하     10\n",
      "      ..\n",
      "정상     1\n",
      "면      1\n",
      "이타     1\n",
      "데      1\n",
      "지능     1\n",
      "Length: 186, dtype: int64]\n",
      "<class 'list'>\n",
      "dicts의 길이 1\n",
      "========================\n",
      "{'심리학', '하지만', '너무', '남자', '나요', '거의', '대부분', '근접', '평균', '을', '그런데', '역시', '를', '살펴봅시다', '이', '못하', '분포', '아주', '는', '통해', '계시', '곡선', '엔', '란', '해서', '적', '모든', '갖춘', '던졌', '들', '말', '잘못', '특정', '98', '열', '던질', '?', '지수', '더', '에게', '맞', '사이', '사실', '이타', '또', '이유', '뭘까요', '일단', '상', '때', '같', '기', '여자', '대비', '성별', '심리학자', '보다', '라는', '심리', '해', '커다란', '나', '선', '차이점', '게', '라면', '습니다', '얼마나', '있', '%', '일컫', '와', '어느', '관한', '화', '만', '데', '것', '일까요', '사람', '은', '정말', ',', '하나', '알아보', '소수', '느냐', '살펴', '.', '걸', '에서', '대해', '고려', '지각', '척도', '도', '하', '상태', '표준', '지능', '지', '그', '겹칠', '뛰어나', '할', '수', '잘', '거든요', '자신', '예측', '입니다', '의', '공간', '겁니다', '봅시다', '공', '작', '번', '간', '겠', '건', '여러분', '중', '건데', '행동', '능력', '읽', '지도', '예', '정상', '가지', '쯤', '한', '타인', '길', '보', '걸까요', '동일', '면', '대략', '보입니다', '심지어', '두', '다고', '어', '된', '거리', '죠', '비슷', '으로', '도록', '에', '확실', '인', '실제로', '지식', '항상', '식', '온', '금성', '화성', '합니다', '여기', '지만', '이나', '신화', '일', '수준', '셨', '가', '왔', '남녀', '시', '살펴보', '정도', '고', '차이', '던지', '법', '여성', '볼', '알', '지성', '위해', '다른', '멀리'}\n",
      "<class 'set'>\n",
      "[.     16\n",
      "는     15\n",
      "들     14\n",
      ",     10\n",
      "하     10\n",
      "      ..\n",
      "정상     1\n",
      "면      1\n",
      "이타     1\n",
      "데      1\n",
      "지능     1\n",
      "Length: 186, dtype: int64, 의      15\n",
      "는      14\n",
      "을      10\n",
      ".      10\n",
      "하       9\n",
      "       ..\n",
      "못하      1\n",
      "성적      1\n",
      "희망      1\n",
      "그런데     1\n",
      "최상      1\n",
      "Length: 195, dtype: int64]\n",
      "<class 'list'>\n",
      "dicts의 길이 2\n",
      "========================\n",
      "{'너무', '\"', '남자', '나요', '이야기', '약간', '형식', '근접', '평균', '유형', '수정', '을', '그런데', '이', '해석', '라요', '분포', '누군가', '는', '엔', '란', '해서', '희망', '인증', '들', '런던', '말', '잘못', '열', '따라서', '기여', '?', '지수', '최근', '더', '맞', '사실', '해야', '이유', '뭘까요', '50', '우등', '같', '내용', '기', '여자', '성별', '심리학자', '상대', '여러', '나', '선', '맞추', '차이점', '게', '라면', '네요', '얼마나', '운전', '%', '와', '어느', '관한', '화', '만', '데', '것', '바로', '일까요', '사람', '은', '듣', ',', '상당수', '소수', '비교', '걸', '고려', '도', '과', '수행', '하', '상태', '이용', '지능', '지', '수치', '그', '겹칠', '또는', '수', '거든요', '예측', '입니다', '아', '겁니다', '조만간', '공', '작', '들립니다', '번', '라', '건', '인지', '환경', '건데', '행동', '능력', '속', '제시', '정밀', '지도', '예', '정상', '58', '결과', '가지', '한', '타인', '보', '시험', '대학교', '동일', '습니까', '보입니다', '심지어', '건축학', '탓', '안', '다고', '거리', '방식', '따라', '되', '해도', '으로', '도록', '중등', '받', '여타', '항상', '배워야', '금성', '화성', '이건', '합니다', '않', '수준', '셨', '남녀', '모두', '정도', '을까요', '차이', '던지', '법', '없이', '알', '급', '매우', '다른', '멀리', '심리학', '하지만', '했', '거의', '대부분', '연립', '역시', '를', '살펴봅시다', '풀', '어야', '는데', '못하', '성', '아주', '통해', '계시', '곡선', '적', '배울', '모든', '갖춘', '더하', '던졌', '사용', '만일', '특정', '경험', '98', '던질', '에게', '100', '사이', '학생', '유전', '이타', '쓰', '공유', '또', '학습', '당신', '일단', '상', '체감', '때', 'A', '자', '대비', '보다', '됩니다', '라는', '수학', '심리', '해', '커다란', '학력', '머리', 'GCSE', '방정식', '습니다', '있', '그러면', '일컫', 'UCL', '된다', '정말', '하나', '던', '알아보', '(', '느냐', '살펴', '.', '에서', '대해', '지각', '척도', '표준', '쌍생아', '춤', '뛰어나', '할', '잘', '자신', '싶', '의', '공간', '봅시다', '좁혀졌', '간', '성적', '좌우', '겠', '여러분', '중', '생', '읽', '!', '연구', '쯤', '어떻게', '길', '걸까요', '면', '여', '비난', '대략', '경우', '똑같이', '한지', '최상', '두', '형제자매', '어', '된', '아니', '죠', ')', '비슷', '종이', '우리', '이란', '에', '확실', '인', '쌍둥이', '실제로', '지식', '식', '온', '여기', '지만', '몸', '이나', '신화', '일', '처럼', '가', '왔', '유전자', '시', '살펴보', '고', '계산', '볼', '여성', '지성', '위해', '요인'}\n",
      "<class 'set'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "만     2\n",
       "%     2\n",
       "라면    2\n",
       ".     2\n",
       "에서    2\n",
       "     ..\n",
       "던졌    1\n",
       "더하    1\n",
       "갖춘    1\n",
       "모든    1\n",
       "너무    1\n",
       "Length: 311, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_document_frequency([doc1, doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['지능', '지수', '라는', '말', '들', '어', '보', '셨', '을', '겁니다', '.', '여러분', '의', '지성', '을', '일컫', '는', '말', '이', '죠', '.', '그런데', '심리', '지수', '란', '건', '뭘까요', '?', '사람', '들', '이', '특정', '한', '식', '으로', '행동', '하', '는', '이유', '에', '대해', '여러분', '은', '얼마나', '알', '고', '계시', '나요', '?', '또', '타인', '이나', '심지어', '여러분', '의', '행동', '을', '예측', '하', '는', '일', '은', '얼마나', '잘', '하', '시', '나요', '?', '또', ',', '심리학', '에', '대해', '갖춘', '지식', '중', '에서', '어느', '정도', '나', '잘못', '된', '것', '일까요', '?', '심리학', '에', '관한', '열', '가지', '신화', '를', '통해', '잘못', '된', '것', '들', '을', '알아보', '도록', '하', '죠', '.', '여러분', '은', '한', '번', '쯤', '들', '어', '보', '셨', '을', '법', '한', '것', '은', '자신', '들', '의', '심리학', '에', '대해', '고려', '할', '때', ',', '거의', '항상', '남자', '는', '화성', '에서', '왔', '고', ',', '여자', '는', '금성', '에서', '온', '것', '같', '다고', '합니다', '.', '하지만', '실제로', '남자', '와', '여자', '는', '얼마나', '다른', '걸까요', '?', '이', '를', '알아보', '기', '위해', ',', '일단', '남녀', '사이', '에', '확실', '하', '게', '차이', '나', '는', '것', '을', '살펴보', '고', '심리학', '적', '인', '성별', '간', '의', '차이점', '을', '동일', '한', '척도', '상', '에서', '대비', '해', '보', '도록', '하', '겠', '습니다', '.', '남자', '와', '여자', '간', '에', '실제로', '차이', '나', '는', '능력', '중', '하나', '는', '그', '들', '이', '공', '을', '얼마나', '멀리', '던질', '수', '있', '느냐', '하', '는', '것', '입니다', '.', '여기', '남자', '들', '의', '데', '이타', '를', '보', '시', '면', ',', '정상', '분포', '곡선', '이', '라는', '걸', '볼', '수', '있', '습니다', '.', '남자', '들', '소수', '는', '정말', '멀리', '던지', '고', ',', '남자', '들', '소수', '는', '멀리', '던지', '지', '못하', '지만', ',', '남자', '들', '대부분', '은', '평균', '적', '인', '거리', '를', '던졌', '습니다', '.', '여자', '들', '도', '역시', '비슷', '한', '분포', '상태', '를', '보입니다', '만', '사실', '남녀', '사이', '엔', '커다란', '차이', '가', '있', '습니다', '.', '사실', ',', '평균', '수준', '의', '남자', '라면', '모든', '여성', '중', '대략', '98', '%', '보다', '더', '멀리', '던질', '수', '있', '거든요', '.', '이', '와', '동일', '하', '게', '표준', '화', '된', '척도', '상', '에서', '심리학', '에서', '말', '하', '는', '성별', '간', '의', '차이', '를', '살펴', '봅시다', '.', '심리학자', '라는', '여러분', '에게', '말', '하', '길', '남자', '들', '의', '공간', '지각', '능력', '이', '여자', '들', '보다', '뛰어나', '다고', '할', '겁니다', '.', '예', '를', '들', '어', ',', '지도', '읽', '는', '능력', '같', '은', '건데', ',', '맞', '는', '말', '입니다', '.', '하지만', '그', '차이', '의', '정도', '를', '살펴봅시다', '.', '아주', '작', '죠', '.', '두', '선', '이', '너무', '근접', '해서', '거의', '겹칠', '정도', '입니다', '.']\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "[.     16\n",
      "는     15\n",
      "들     14\n",
      ",     10\n",
      "하     10\n",
      "      ..\n",
      "정상     1\n",
      "면      1\n",
      "이타     1\n",
      "데      1\n",
      "지능     1\n",
      "Length: 186, dtype: int64]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## series를 list로 감싸면 뭐가 되지??\n",
    "test = [get_term_frequency(doc1)]\n",
    "print(type(test))\n",
    "print(test)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드 의문점\n",
    "1. (get_term_frequency 함수에서) if word_dict is None으로 조건을 거는 부분이 반드시 필요한가? word_dict가 None이 아닌 경우가 존재할까? 그냥 애초에 word_dict를 받지 말고 함수 안에서만 정의해서 사용하면 안되는건가?\n",
    "-> Series가 count_values() 계산이 더 빠르기 때문에 Series로 반환  \n",
    "2. get_term_frequency에서 단어 등장횟수 딕셔너리를 만들 때.. for문을 이용하지 않고 더 빠르게 만드는 방법은 없을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = [1,'a','d',4,5]\n",
    "auth_series = pd.Series(author, index = [1,2,'a','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(auth_series[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(auth_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF의 최종 함수\n",
    "\n",
    "def get_tfidf(docs): ## 각 문서를 list로 받음\n",
    "    vocab = {}\n",
    "    tfs = []\n",
    "    for d in docs:\n",
    "        vocab = get_term_frequency(d, vocab)   # vocab = 단어 빈도 Series (TF)\n",
    "        tfs += [get_term_frequency(d)]  # 문서 순서대로 TF Series를 list로 저장\n",
    "    df = get_document_frequency(docs)  # 단어의 IDF\n",
    "\n",
    "    from operator import itemgetter\n",
    "    '''\n",
    "    f = itemgetter(2), the call f(r) returns r[2].\n",
    "    g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3]).\n",
    "    '''\n",
    "    import numpy as np\n",
    "\n",
    "    stats = []\n",
    "    for word, freq in vocab.items():\n",
    "        tfidfs = []\n",
    "        for idx in range(len(docs)):\n",
    "            if tfs[idx].get(word) is not None:  ## i번째 문서 단어열(tfs[idx])에서 특정 단어의 빈도(TF)가 0이 아니면\n",
    "                tfidfs += [tfs[idx][word] * np.log(len(docs) / df[word])] ## TF * 역문서빈도 log(문서개수/단어가 문서에 나타난 빈도)\n",
    "            else:\n",
    "                tfidfs += [0] ## 만약 빈도가 0이면 TF-IDF는 분자가 0이므로 계산 필요성 X\n",
    "\n",
    "        stats.append((word, freq, *tfidfs, max(tfidfs)))\n",
    "\n",
    "    return pd.DataFrame(stats, columns=('word',\n",
    "                                        'frequency',\n",
    "                                        'doc1',\n",
    "                                        'doc2',\n",
    "                                        'doc3',\n",
    "                                        'max')).sort_values('max', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[.     16\n",
      "는     15\n",
      "들     14\n",
      ",     10\n",
      "하     10\n",
      "      ..\n",
      "정상     1\n",
      "면      1\n",
      "이타     1\n",
      "데      1\n",
      "지능     1\n",
      "Length: 186, dtype: int64]\n",
      "<class 'list'>\n",
      "dicts의 길이 1\n",
      "========================\n",
      "{'심리학', '하지만', '너무', '남자', '나요', '거의', '대부분', '근접', '평균', '을', '그런데', '역시', '를', '살펴봅시다', '이', '못하', '분포', '아주', '는', '통해', '계시', '곡선', '엔', '란', '해서', '적', '모든', '갖춘', '던졌', '들', '말', '잘못', '특정', '98', '열', '던질', '?', '지수', '더', '에게', '맞', '사이', '사실', '이타', '또', '이유', '뭘까요', '일단', '상', '때', '같', '기', '여자', '대비', '성별', '심리학자', '보다', '라는', '심리', '해', '커다란', '나', '선', '차이점', '게', '라면', '습니다', '얼마나', '있', '%', '일컫', '와', '어느', '관한', '화', '만', '데', '것', '일까요', '사람', '은', '정말', ',', '하나', '알아보', '소수', '느냐', '살펴', '.', '걸', '에서', '대해', '고려', '지각', '척도', '도', '하', '상태', '표준', '지능', '지', '그', '겹칠', '뛰어나', '할', '수', '잘', '거든요', '자신', '예측', '입니다', '의', '공간', '겁니다', '봅시다', '공', '작', '번', '간', '겠', '건', '여러분', '중', '건데', '행동', '능력', '읽', '지도', '예', '정상', '가지', '쯤', '한', '타인', '길', '보', '걸까요', '동일', '면', '대략', '보입니다', '심지어', '두', '다고', '어', '된', '거리', '죠', '비슷', '으로', '도록', '에', '확실', '인', '실제로', '지식', '항상', '식', '온', '금성', '화성', '합니다', '여기', '지만', '이나', '신화', '일', '수준', '셨', '가', '왔', '남녀', '시', '살펴보', '정도', '고', '차이', '던지', '법', '여성', '볼', '알', '지성', '위해', '다른', '멀리'}\n",
      "<class 'set'>\n",
      "[.     16\n",
      "는     15\n",
      "들     14\n",
      ",     10\n",
      "하     10\n",
      "      ..\n",
      "정상     1\n",
      "면      1\n",
      "이타     1\n",
      "데      1\n",
      "지능     1\n",
      "Length: 186, dtype: int64, 의      15\n",
      "는      14\n",
      "을      10\n",
      ".      10\n",
      "하       9\n",
      "       ..\n",
      "못하      1\n",
      "성적      1\n",
      "희망      1\n",
      "그런데     1\n",
      "최상      1\n",
      "Length: 195, dtype: int64]\n",
      "<class 'list'>\n",
      "dicts의 길이 2\n",
      "========================\n",
      "{'너무', '\"', '남자', '나요', '이야기', '약간', '형식', '근접', '평균', '유형', '수정', '을', '그런데', '이', '해석', '라요', '분포', '누군가', '는', '엔', '란', '해서', '희망', '인증', '들', '런던', '말', '잘못', '열', '따라서', '기여', '?', '지수', '최근', '더', '맞', '사실', '해야', '이유', '뭘까요', '50', '우등', '같', '내용', '기', '여자', '성별', '심리학자', '상대', '여러', '나', '선', '맞추', '차이점', '게', '라면', '네요', '얼마나', '운전', '%', '와', '어느', '관한', '화', '만', '데', '것', '바로', '일까요', '사람', '은', '듣', ',', '상당수', '소수', '비교', '걸', '고려', '도', '과', '수행', '하', '상태', '이용', '지능', '지', '수치', '그', '겹칠', '또는', '수', '거든요', '예측', '입니다', '아', '겁니다', '조만간', '공', '작', '들립니다', '번', '라', '건', '인지', '환경', '건데', '행동', '능력', '속', '제시', '정밀', '지도', '예', '정상', '58', '결과', '가지', '한', '타인', '보', '시험', '대학교', '동일', '습니까', '보입니다', '심지어', '건축학', '탓', '안', '다고', '거리', '방식', '따라', '되', '해도', '으로', '도록', '중등', '받', '여타', '항상', '배워야', '금성', '화성', '이건', '합니다', '않', '수준', '셨', '남녀', '모두', '정도', '을까요', '차이', '던지', '법', '없이', '알', '급', '매우', '다른', '멀리', '심리학', '하지만', '했', '거의', '대부분', '연립', '역시', '를', '살펴봅시다', '풀', '어야', '는데', '못하', '성', '아주', '통해', '계시', '곡선', '적', '배울', '모든', '갖춘', '더하', '던졌', '사용', '만일', '특정', '경험', '98', '던질', '에게', '100', '사이', '학생', '유전', '이타', '쓰', '공유', '또', '학습', '당신', '일단', '상', '체감', '때', 'A', '자', '대비', '보다', '됩니다', '라는', '수학', '심리', '해', '커다란', '학력', '머리', 'GCSE', '방정식', '습니다', '있', '그러면', '일컫', 'UCL', '된다', '정말', '하나', '던', '알아보', '(', '느냐', '살펴', '.', '에서', '대해', '지각', '척도', '표준', '쌍생아', '춤', '뛰어나', '할', '잘', '자신', '싶', '의', '공간', '봅시다', '좁혀졌', '간', '성적', '좌우', '겠', '여러분', '중', '생', '읽', '!', '연구', '쯤', '어떻게', '길', '걸까요', '면', '여', '비난', '대략', '경우', '똑같이', '한지', '최상', '두', '형제자매', '어', '된', '아니', '죠', ')', '비슷', '종이', '우리', '이란', '에', '확실', '인', '쌍둥이', '실제로', '지식', '식', '온', '여기', '지만', '몸', '이나', '신화', '일', '처럼', '가', '왔', '유전자', '시', '살펴보', '고', '계산', '볼', '여성', '지성', '위해', '요인'}\n",
      "<class 'set'>\n",
      "[.     16\n",
      "는     15\n",
      "들     14\n",
      ",     10\n",
      "하     10\n",
      "      ..\n",
      "정상     1\n",
      "면      1\n",
      "이타     1\n",
      "데      1\n",
      "지능     1\n",
      "Length: 186, dtype: int64, 의      15\n",
      "는      14\n",
      "을      10\n",
      ".      10\n",
      "하       9\n",
      "       ..\n",
      "못하      1\n",
      "성적      1\n",
      "희망      1\n",
      "그런데     1\n",
      "최상      1\n",
      "Length: 195, dtype: int64, 을       21\n",
      "는       18\n",
      "이       16\n",
      "하       14\n",
      ",       11\n",
      "        ..\n",
      "들으시는     1\n",
      "아서       1\n",
      "앉        1\n",
      "거기       1\n",
      "그러나      1\n",
      "Length: 205, dtype: int64]\n",
      "<class 'list'>\n",
      "dicts의 길이 3\n",
      "========================\n",
      "{'너무', '\"', '전', '앉', '남자', '나요', '이야기', '약간', '친척', '형식', '다면', '근접', '평균', '유형', '수정', '을', '그런데', '롭', ':', '참', '들으시는', '영구', '아서', '이', '해석', '라요', '분포', '누군가', '는', '치명', '았', '엔', '란', '가장', '해서', '희망', '인증', '들', '런던', '말', '잘못', '실제', '분석', '운', '열', '따라서', '기여', '?', '지수', '최근', '더', '가해진', '몸짓', '참여', '맞', '사실', '제', '저', '해야', '오래', '이유', '뭘까요', '첫째', '50', '우등', '같', '내용', '기', '여자', '왜냐하면', '성별', '심리학자', '상대', '마다', '인터뷰', '동료', '손상', '행해진', '남기', '여러', '나', '선', '가능', '맞추', '차이점', '게', '라면', '해결', '네요', '얼마나', '운전', '과학', '%', '와', '어느', '관한', '화', '만', '데', '것', '바로', '일까요', '사람', '은', '듣', '목적', '시키', ',', '상당수', '소수', '비교', '할까', '걸', '고려', '도', '과', '수행', '하', '상태', '불편', '오랜', '이용', '지능', '흰색', '지', '수치', '그', '겹칠', '또는', '라고', '포함', '수', '거든요', '예측', '입니다', '아', '전기', '겁니다', '때문', '조만간', '려고', 'TV', '공', '작', '들립니다', '번', '라', '건', '인지', '환경', '건데', '행동', '거', '능력', '속', '제시', '셋째', '로', '정밀', '함', '지도', '예', '정상', '58', '결과', '가지', '강한', '수백', '한', '타인', '보', '시험', '대학교', '동일', '신념', '습니까', '보입니다', '동안', '심지어', '건축학', '탓', '안', '다고', '거리', '면서', '방식', '따라', '되', '해도', '으로', '도록', '중등', '받', '으며', '여타', '항상', '배워야', '금성', '화성', '이건', '합니다', '었', '는데요', '호소', '생각', '않', '상기', '수준', '셨', '남녀', '모두', '정도', '을까요', '실패', '차이', '던지', '법', '없이', '비록', '밝혔', '알', '급', '매우', '다른', '멀리', '거기', '심리학', '하지만', '했', '세월', '거의', '대부분', '실종', '다', '연립', '역시', '검사', '분', '를', '니', '살펴봅시다', '풀', '어야', '가운', '걸쳐', '는데', '못하', '성', '아주', '가치', '통해', '계시', '곡선', '흥미', '고통', '경찰관', '적', '배울', '모든', '갖춘', '더하', '던졌', '탐정', '사용', '만일', '특정', '경험', '어떤', '98', '그러나', '던질', '실험', '점', '밖', '에게', '100', '거짓말', '사이', '학생', '유전', '이타', '쓰', '공유', '걱정', '또', '학습', '당신', '일단', '상', '체감', '때', 'A', '자', '대비', \"'\", '벌써', '보다', '탐지', '표현', '됩니다', '스럽', '라는', '수학', '심리', '해', '완전히', '커다란', '학력', '머리', '단지', 'GCSE', '회색', '말투', '방정식', '없', '습니다', '인해', '그러', '있', '그러면', '일컫', '위해서', 'UCL', '된다', '정말', '하나', '던', '알아보', '(', '느냐', '살펴', '.', '에서', '대해', '지각', '처벌', '척도', '표준', '쌍생아', '기본', '춤', '뛰어나', '찾', '순간', '할', '둘째', '지금', '잘', '남', '자신', '싶', '12', '의', '공간', '봅시다', '시켜', '좁혀졌', '간', '끝나', '달', '성적', '좌우', '겠', '회', '여러분', '중', '생', '홍보', '알아내', '읽', '!', '여부', '연구', '쯤', '어떻게', '예외', '길', '걸까요', '세', '면', '주지', '여', '비난', '언어', '대략', '경우', '똑같이', '한지', '최상', '얻', '두', '형제자매', '어', '된', '아니', '죠', ')', '비슷', '종이', '아마', '반해서', '우리', '이란', '에', '확실', '인', '입', '쌍둥이', '실제로', '지식', '식', '온', '성과', '여기', '지만', '몸', '충격', '이나', '신화', '일', '처럼', '패턴', '진실', '가', '왔', '유전자', '시', '실험실', '살펴보', '고', '계산', '볼', '여성', '지성', '위해', '중요', '요인'}\n",
      "<class 'set'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>남자</td>\n",
       "      <td>9</td>\n",
       "      <td>9.887511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.887511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>요인</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.591674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.591674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>심리학</td>\n",
       "      <td>5</td>\n",
       "      <td>5.493061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.493061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>었</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>4.394449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>제</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.394449</td>\n",
       "      <td>4.394449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>라는</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>중</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>습니다</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>보</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>는</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  frequency      doc1      doc2      doc3       max\n",
       "23   남자          9  9.887511  0.000000  0.000000  9.887511\n",
       "37   요인          6  0.000000  6.591674  0.000000  6.591674\n",
       "51  심리학          5  5.493061  0.000000  0.000000  5.493061\n",
       "57    었          4  0.000000  0.000000  4.394449  4.394449\n",
       "63    제          4  0.000000  0.000000  4.394449  4.394449\n",
       "..  ...        ...       ...       ...       ...       ...\n",
       "36   라는          6  0.000000  0.000000  0.000000  0.000000\n",
       "33    중          6  0.000000  0.000000  0.000000  0.000000\n",
       "30  습니다          7  0.000000  0.000000  0.000000  0.000000\n",
       "29    보          7  0.000000  0.000000  0.000000  0.000000\n",
       "0     는         47  0.000000  0.000000  0.000000  0.000000\n",
       "\n",
       "[437 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tfidf([doc1, doc2, doc3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
